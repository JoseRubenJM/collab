{"ast":null,"code":"/*!\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\nimport { ChildLogger } from \"@fluidframework/telemetry-utils\";\nimport { FileMode, TreeEntry } from \"@fluidframework/protocol-definitions\";\nimport { NonCollabClient, UnassignedSequenceNumber } from \"./constants\";\nimport * as Properties from \"./properties\";\nimport { serializeAsMinSupportedVersion } from \"./snapshotChunks\";\nexport let SnapshotLegacy = /*#__PURE__*/(() => {\n  class SnapshotLegacy {\n    constructor(mergeTree, logger, filename, onCompletion) {\n      var _a, _b, _c;\n      this.mergeTree = mergeTree;\n      this.filename = filename;\n      this.onCompletion = onCompletion;\n      this.logger = ChildLogger.create(logger, \"Snapshot\");\n      this.chunkSize = (_c = (_b = (_a = mergeTree) === null || _a === void 0 ? void 0 : _a.options) === null || _b === void 0 ? void 0 : _b.mergeTreeSnapshotChunkSize, _c !== null && _c !== void 0 ? _c : SnapshotLegacy.sizeOfFirstChunk);\n    }\n    getSeqLengthSegs(allSegments, allLengths, approxSequenceLength, startIndex = 0) {\n      const segs = [];\n      let sequenceLength = 0;\n      let segCount = 0;\n      while (sequenceLength < approxSequenceLength && startIndex + segCount < allSegments.length) {\n        const pseg = allSegments[startIndex + segCount];\n        segs.push(pseg);\n        sequenceLength += allLengths[startIndex + segCount];\n        segCount++;\n      }\n      return {\n        version: undefined,\n        chunkStartSegmentIndex: startIndex,\n        chunkSegmentCount: segCount,\n        chunkLengthChars: sequenceLength,\n        totalLengthChars: this.header.segmentsTotalLength,\n        totalSegmentCount: allSegments.length,\n        chunkSequenceNumber: this.header.seq,\n        segmentTexts: segs\n      };\n    }\n    /**\n     * Emits the snapshot to an ITree. If provided the optional IFluidSerializer will be used when serializing\n     * the summary data rather than JSON.stringify.\n     */\n    emit(catchUpMsgs, serializer, bind) {\n      var _a, _b;\n      const chunk1 = this.getSeqLengthSegs(this.segments, this.segmentLengths, this.chunkSize);\n      let length = chunk1.chunkLengthChars;\n      let segments = chunk1.chunkSegmentCount;\n      const tree = {\n        entries: [{\n          mode: FileMode.File,\n          path: SnapshotLegacy.header,\n          type: TreeEntry.Blob,\n          value: {\n            contents: serializeAsMinSupportedVersion(SnapshotLegacy.header, chunk1, this.logger, this.mergeTree.options, serializer, bind),\n            encoding: \"utf-8\"\n          }\n        }],\n        id: null\n      };\n      if (chunk1.chunkSegmentCount < chunk1.totalSegmentCount) {\n        const chunk2 = this.getSeqLengthSegs(this.segments, this.segmentLengths, this.header.segmentsTotalLength, chunk1.chunkSegmentCount);\n        length += chunk2.chunkLengthChars;\n        segments += chunk2.chunkSegmentCount;\n        tree.entries.push({\n          mode: FileMode.File,\n          path: SnapshotLegacy.body,\n          type: TreeEntry.Blob,\n          value: {\n            contents: serializeAsMinSupportedVersion(SnapshotLegacy.body, chunk2, this.logger, this.mergeTree.options, serializer, bind),\n            encoding: \"utf-8\"\n          }\n        });\n      }\n      this.logger.shipAssert(length === this.header.segmentsTotalLength, {\n        eventName: \"emit: mismatch in segmentsTotalLength\"\n      });\n      this.logger.shipAssert(segments === chunk1.totalSegmentCount, {\n        eventName: \"emit: mismatch in totalSegmentCount\"\n      });\n      tree.entries.push({\n        mode: FileMode.File,\n        path: (_b = (_a = this.mergeTree.options) === null || _a === void 0 ? void 0 : _a.catchUpBlobName, _b !== null && _b !== void 0 ? _b : SnapshotLegacy.catchupOps),\n        type: TreeEntry.Blob,\n        value: {\n          contents: serializer ? serializer.stringify(catchUpMsgs, bind) : JSON.stringify(catchUpMsgs),\n          encoding: \"utf-8\"\n        }\n      });\n      return tree;\n    }\n    extractSync() {\n      const collabWindow = this.mergeTree.getCollabWindow();\n      this.seq = collabWindow.minSeq;\n      this.header = {\n        segmentsTotalLength: this.mergeTree.getLength(this.mergeTree.collabWindow.minSeq, NonCollabClient),\n        seq: this.mergeTree.collabWindow.minSeq\n      };\n      const segs = [];\n      let prev;\n      const extractSegment =\n      // eslint-disable-next-line max-len\n      (segment, pos, refSeq, clientId, start, end) => {\n        // eslint-disable-next-line eqeqeq\n        if (segment.seq != UnassignedSequenceNumber && segment.seq <= this.seq && (\n        // eslint-disable-next-line eqeqeq\n        segment.removedSeq === undefined || segment.removedSeq == UnassignedSequenceNumber || segment.removedSeq > this.seq)) {\n          if (prev && prev.canAppend(segment) && Properties.matchProperties(prev.properties, segment.properties)) {\n            prev = prev.clone();\n            prev.append(segment.clone());\n          } else {\n            if (prev) {\n              segs.push(prev);\n            }\n            prev = segment;\n          }\n        }\n        return true;\n      };\n      this.mergeTree.map({\n        leaf: extractSegment\n      }, this.seq, NonCollabClient);\n      if (prev) {\n        segs.push(prev);\n      }\n      this.segments = [];\n      this.segmentLengths = [];\n      let totalLength = 0;\n      segs.map(segment => {\n        totalLength += segment.cachedLength;\n        this.segments.push(segment.toJSONObject());\n        this.segmentLengths.push(segment.cachedLength);\n      });\n      // We observed this.header.segmentsTotalLength < totalLength to happen in some cases\n      // When this condition happens, we might not write out all segments in getSeqLengthSegs()\n      // when writing out \"body\". Issue #1995 tracks following up on the core of the problem.\n      // In the meantime, this code makes sure we will write out all segments properly\n      // eslint-disable-next-line eqeqeq\n      if (this.header.segmentsTotalLength != totalLength) {\n        this.logger.sendErrorEvent({\n          eventName: \"SegmentsTotalLengthMismatch\",\n          totalLength,\n          segmentsTotalLength: this.header.segmentsTotalLength\n        });\n        this.header.segmentsTotalLength = totalLength;\n      }\n      return this.segments;\n    }\n  }\n  SnapshotLegacy.header = \"header\";\n  SnapshotLegacy.body = \"body\";\n  SnapshotLegacy.catchupOps = \"catchupOps\";\n  // Split snapshot into two entries - headers (small) and body (overflow) for faster loading initial content\n  // Please note that this number has no direct relationship to anything other than size of raw text (characters).\n  // As we produce json for the blob (and then encode into base64 and send over the wire compressed), this number\n  // is really hard to correlate with any actual metric that matters (like bytes over the wire).\n  // For test with small number of chunks it would be closer to blob size (before base64 encoding),\n  // for very chunky text, blob size can easily be 4x-8x of that number.\n  //# sourceMappingURL=snapshotlegacy.js.map\n  SnapshotLegacy.sizeOfFirstChunk = 10000;\n  return SnapshotLegacy;\n})();","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}